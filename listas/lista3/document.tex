% !TeX document-id = {1c0b4298-276a-4038-8e08-c4a1f4846da7}
% !TeX TXS-program:bibliography = txs:///biber
\documentclass[10pt,a4paper]{article}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{thmtools}
\usepackage{xcolor}
\usepackage{nameref}
\usepackage{hyperref}
\usepackage{color}
\usepackage{float}

\usepackage[
backend=biber,
style=authoryear,
natbib=true
]{biblatex}
\addbibresource{../bibliography.bib}


\title{\large Proabilidade e Estatística}
\author{\normalsize Exercícios sobre Convergência Estocástica}
\date{}
\begin{document}
	\maketitle
 \paragraph{Exercício 1} Considere o espaço de probabilidade $(\{0,1\}, 2^{\{0,1\}},\mathbb{P})$, com $\mathbb{P}[\{0\}]=1/2$. Considere a sequência de variáveis aleatórias $X_n = \mathbf{1}_{\{1\}}$ para todo $n \in \mathbb{N}$ e $X = \mathbf{1}_{\{0\}}$. Mostre que $X_n \overset{d}{\to} X$, mas que não há convergência em probabilidade de $X_n$ a $X$.
 \paragraph{Exercício 2} Considere o espaço de probabilidade $([0,1], \mathcal{B}[0,1],\lambda)$, com $\lambda$ a medida uniforme. Considere a sequência de variáveis aleatórias:
 
 \begin{align*}
 	X_1 = \mathbf{1}_{[0,1]}  \\
 	X_2 = \mathbf{1}_{[0,1]} +\mathbf{1}_{[0,1/2]} \\
 	 X_3 = \mathbf{1}_{[0,1]} +\mathbf{1}_{[1/2,1]} \\
 	  	 X_4 = \mathbf{1}_{[0,1]} +\mathbf{1}_{[0,1/3]} \\
 	  	  	  	 X_5 = \mathbf{1}_{[0,1]} +\mathbf{1}_{[1/3,2/3]} \\
 	  	  	  	  	  	 X_6 = \mathbf{1}_{[0,1]} +\mathbf{1}_{[2/3,1]} \\
 	  	  	  	  	  	  	  	  	  	  	  	 X_7 = \mathbf{1}_{[0,1]} +\mathbf{1}_{[0,1/4]} \\
 	  	  	  	  	  	 \vdots 
 \end{align*}
 \begin{itemize}
 	\item[a] Mostre que, para todo $\omega \in [0,1]$, a sequência $(X_n(\omega))_{n \in \mathbb{N}}$ \textbf{não converge}. Conclua que não $X_n$ não converge quase certamente.
 	\item[b] Mostre que $X_n \overset{p}{\to} X_1$.
 \end{itemize}
 
 \paragraph{Exercício 3} Seja $X_n$ uma sequência de variáveis aelatórias, que converge em distribuição a uma variável aleatória $X$. Mostre que, se a função distribuição $F_{X}$ de $X$ é contínua, então:
 $$\lim_{n\to \infty}\sup_{s\in (-\infty,\infty)} |F_{X_n}(s) - F_X(s)| = 0\, .$$
 
 \noindent \textit{Dica:} considere $k \in \mathbb{N}$ e use continuidade para encontrar pontos $s_1,s_2,\ldots,s_{k}$ tais que $F_{X}(s_j) =\frac{j}{k+1}$. Use esses pontos para limitar por cima o supremo.
 
  \paragraph{Exercício 4} No que segue, sejam $X_n$ e $Y_n$ duas sequências de variáveis aleatórias definidas num mesmo espaço de probabilidade, e $a_n$ e $b_n$ duas sequências de números reais. Mostre que:
  \begin{enumerate}
  	\item $X_n = O_P(1)$ se, e somente se, para toda sequência de números reais $\epsilon_n \uparrow \infty$, tem-se que $\lim_{n \to \infty} \mathbb{P}[|X_n|>\epsilon_n ] = 0$.
  	\item Se $X_n = O_P(a_n)$ e $a_n \downarrow 0$, então $X_n = o_P(1)$.
  	  	\item Se $X_n = o_P(a_n)$, então $X_n = O_P(a_n)$.
  	  	  	  	\item Se $X_n = O_P(a_n)$ e $Y_n = O_P(b_n)$  então $X_n Y_n = O_P(a_n b_n)$. e $X_n +Y_n = O_P(\max\{a_n,b_n\})$.
  	  	  	  	\item Se, para $r>0$, $\mathbb{E}[|X_n|^r] < \infty$ para todo $n \in \mathbb{N}$ então $X_n  = O_P(\lVert X_n \rVert_r)$. \textit{Dica:} use a desigualdade de Markov.
  \end{enumerate} 

\paragraph{Exercício 5} Sejam $X_1, X_2, \ldots, X_n$ duas variáveis aleatórias definidas num mesmo espaço de probabilidade. Mostre que essas variáveis aleatórias são independentes se, e somente se, definindo o vetor aleatório $\boldsymbol{X}=(X_1,X_2,\ldots,X_n)'$, a função caractéristica de $\boldsymbol{X}$ satisfaz:

$$\phi_{\boldsymbol{X}}(s)= \prod_{i=1}^n \phi_{X_i}(s_i)\,, \quad \forall s \in \mathbb{R}^n\, .$$

\paragraph{Exercício 6} Sejam $\boldsymbol{X} = (X_1,X_2,\ldots,X_n)'$ um vetor de variáveis aleatórias definidas no mesmo espaço de probabilidade. Dizemos que $\boldsymbol{X}$ segue distribuição normal com média $\boldsymbol{\mu} \in \mathbb{R}^{n}$ e matriz de variância-covariância $\Sigma \in \{A \in \mathbb{R}^{n \times n}: A \text{ positiva semidefinida}\}$, denotado por $\boldsymbol{X}\sim \mathcal{N}(\mathbb{\mu},\boldsymbol{\Sigma})$ se a medida induzida $\mathbb{P}_{\boldsymbol{X}}$ admite densidade (com respeito à medida de Lebesgue em $\mathbb{R}^n$) dada por:

$$f(\boldsymbol{s}) =\frac{1}{(2\pi)^{n/2} \sqrt{\operatorname{det}(\Sigma)}}\exp\left(-\frac{1}{2}(\boldsymbol{s}-\boldsymbol{\mu})'\Sigma (\boldsymbol{s}-\boldsymbol{\mu})\right)\, .$$

Nesse caso, é possível mostrar que $\mathbb{E}[X_j] =\boldsymbol{\mu}_j$ e $\Sigma_{i,j} = \mathbb{C}(\boldsymbol{X}_i,\boldsymbol{X}_j)$ para todo $i,j=1,\ldots, n$.
\begin{itemize}
	\item[a] Mostre que $X_1,\ldots,X_n$ são independentes se, e somente se, $ \mathbb{C}(\boldsymbol{X}_i,\boldsymbol{X}_j) = 0$ para $i\neq j$. \textit{Dica:} a função característica de $\boldsymbol{X}$ é  $\boldsymbol{s}\mapsto \exp(i\boldsymbol{\mu}'\boldsymbol{s} - (1/2)\boldsymbol{s}'\Sigma \boldsymbol{s})$.
	\item[b] A equivalência anterior também é verdadeira pra qualquer distribuição não normal?  
\end{itemize}

\paragraph{Exercício 7} Seja $\boldsymbol{X}_1,\boldsymbol{X}_2,\ldots$ uma sequência de vetores aleatórios $k$-dimensionais iid com $\mathbb{V}[\boldsymbol{X}_{1,l}]<\infty$, para $l=1\ldots, k$. Denote por $\boldsymbol{\mu} \in \mathbb{R}^k$ o vetor com $j$-ésima entrada dada por $\boldsymbol{\mu}_j = \mathbb{E}[\boldsymbol{X}_{1,j}]$ e $\Sigma$ a matriz $k\times k$ com entrada $(i,j)$ dada por $\Sigma_{i,j} = \mathbb{C}(\boldsymbol{X}_{1,i},\boldsymbol{X}_{1,j})$ Use o dispositivo de Crámer-Wold para mostrar que, quando $n \to \infty$:

$$\frac{1}{\sqrt{n}}\sum_{j=1}^n(\boldsymbol{X}_j -\boldsymbol{\mu})\overset{d}{\to}\mathcal{N}(\boldsymbol{0},\Sigma)$$

\paragraph{Exercício 8} Seja $(X_n)_n$ uma sequência de variáveis aleatórias. Suponha que $X_n \overset{d}{\to}c$, onde $c \in \mathbb{R}^k$ é uma \textbf{constante}. Mostre que $X_n \overset{p}{\to} c$.
\end{document}